{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThanhQuyen1/ML/blob/main/Lab_7_21130508_NguyenThanhQuyen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab deals with **GridSearchCV** for tuning the hyper-parameters of an estimator and applying vectorization techniques to the **movie reviews dataset** for classification task.\n",
        "\n",
        "*   **Deadline: 23:59, 22/4/2024 (lớp TH thứ 3) || 29/4/2024 (lớp TH thứ 5)**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "cross_validation:chia tập dữ liệu ra thành k phần\n",
        "ví dụ: chia tập thành 5 phần thì nó sẽ chạy 5 lần\n",
        "lần1: lấy phần đầu để test cho 4 phần còn lại\n",
        "lần2: lấy phần 2 để test cho 4 phần còn lại..."
      ],
      "metadata": {
        "id": "VGOhb-pbRB7e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV: dùng cách tổ hợp các param lại với nhau nên việc tạo param_grid với số lượng lớn sẽ phải tốn lượng lớn thời gian để chạy hết các tổ hợp đó nên việc giới hạn số lượng param lại thành 3x3 sẽ tỗi ưu thời gian chạy hơn\n"
      ],
      "metadata": {
        "id": "7zfXEW7vSPB6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import seaborn as sns\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pylab as plt\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import datasets\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. With **iris** dataset\n",
        "*  1.1. Apply **GridSearchCV** for **SVM** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x_dG9SA5OhGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "data_iris = load_iris(as_frame=True)\n",
        "X = data_iris.data\n",
        "y = data_iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42);\n"
      ],
      "metadata": {
        "id": "nqMrrRwwR2lt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "param_grid_svm = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "svm_alg = svm.SVC(kernel=\"poly\")\n",
        "\n",
        "grid_svm = GridSearchCV(\n",
        "    estimator= svm_alg,\n",
        "    param_grid= param_grid_svm,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=4,\n",
        "    cv =10,\n",
        "    refit = True,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "grid_svm.fit(X_train, y_train)\n",
        "\n",
        "best_svm = grid_svm.best_params_\n",
        "best_svm_score = grid_svm.best_score_\n",
        "print(\"Best parameter: \" , best_svm)\n",
        "\n",
        "y_pred = grid_svm.predict(X_test)\n",
        "accuracy_svm = accuracy_score(y_test, y_pred)\n",
        "precision_svm = precision_score(y_test, y_pred, average='macro')\n",
        "recall_svm = recall_score(y_test, y_pred, average='macro')\n",
        "f1_svm= f1_score(y_test, y_pred, average='macro')\n"
      ],
      "metadata": {
        "id": "62jExOZ952fF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4395272f-660f-4956-f761-8217f245ad47"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameter:  {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  1.2. Apply **GridSearchCV** for **kNN** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "```\n",
        "where\n",
        "\n",
        "    *  **n_neighbors**: Decide the best k based on the values we have computed earlier.\n",
        "    *  **weights**: Check whether adding weights to the data points is beneficial to the model or not. 'uniform' assigns no weight, while 'distance' weighs points by the inverse of their distances meaning nearer points will have more weight than the farther points.\n",
        "    *  **metric**: The distance metric to be used will calculating the similarity.\n"
      ],
      "metadata": {
        "id": "2g--8cng53sY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "param_grid_Knn = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "grid_Knn = GridSearchCV(\n",
        "    estimator= knn,\n",
        "    param_grid= param_grid_Knn,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=4,\n",
        "    cv =10,\n",
        "    refit = True,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "grid_Knn.fit(X_train, y_train)\n",
        "\n",
        "best_Knn = grid_Knn.best_params_\n",
        "best_Knn_score = grid_Knn.best_score_\n",
        "\n",
        "print(\"Best parameter: \" , best_Knn)\n",
        "\n",
        "y_pred = grid_Knn.predict(X_test)\n",
        "accuracy_Knn = accuracy_score(y_test, y_pred)\n",
        "precision_Knn = precision_score(y_test, y_pred, average='macro')\n",
        "recall_Knn = recall_score(y_test, y_pred, average='macro')\n",
        "f1_Knn= f1_score(y_test, y_pred, average='macro')"
      ],
      "metadata": {
        "id": "fX0_kItYPism",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "eb71a28b-d597-4bc8-f253-d071aae256d6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameter:  {'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'uniform'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  1.3. Apply **GridSearchCV** for **Random Forest** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "3lQSOcjL_TIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "grid_rf = GridSearchCV(\n",
        "    estimator= clf,\n",
        "    param_grid= param_grid_rf,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=4,\n",
        "    cv =10,\n",
        "    refit = True,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "best_rf = grid_rf.best_params_\n",
        "best_rf_score = grid_rf.best_score_\n",
        "print(\"Best parameter: \" , best_rf)\n",
        "\n",
        "y_pred = grid_rf.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred)\n",
        "precision_rf = precision_score(y_test, y_pred, average='macro')\n",
        "recall_rf = recall_score(y_test, y_pred, average='macro')\n",
        "f1_rf= f1_score(y_test, y_pred, average='macro')"
      ],
      "metadata": {
        "id": "OlyF9WpN_01p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1e25482c-e70e-420d-e38a-4c0f26992977"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameter:  {'max_depth': 3, 'max_features': 'sqrt', 'max_leaf_nodes': 9, 'n_estimators': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2OwptWLHXdf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   1.4 Compare the best obtained results from 1.1 to 1.3 (use PrettyTable to dispaly the results)"
      ],
      "metadata": {
        "id": "G3N7TD7s_3Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table = PrettyTable()\n",
        "table.field_names = ['ALGORITHM', 'ACC','PRE','RECALL', 'F1']\n",
        "table.add_row(['SVM', accuracy_svm, precision_svm, recall_svm, f1_svm])\n",
        "table.add_row(['Knn', accuracy_Knn, precision_Knn, recall_Knn, f1_Knn])\n",
        "table.add_row(['Random Forest', accuracy_rf, precision_rf, recall_rf, f1_rf])\n",
        "print(table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jFab1KkBTo3W",
        "outputId": "61d86864-9f8a-4822-c185-3133947fc60a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----+-----+--------+-----+\n",
            "|   ALGORITHM   | ACC | PRE | RECALL |  F1 |\n",
            "+---------------+-----+-----+--------+-----+\n",
            "|      SVM      | 1.0 | 1.0 |  1.0   | 1.0 |\n",
            "|      Knn      | 1.0 | 1.0 |  1.0   | 1.0 |\n",
            "| Random Forest | 1.0 | 1.0 |  1.0   | 1.0 |\n",
            "+---------------+-----+-----+--------+-----+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2.\n",
        "For breast cancer dataset (https://tinyurl.com/3vme8hr3) which could be loaded from datasets in sklearn as follows:\n",
        "\n",
        "```\n",
        "#Import scikit-learn dataset library\n",
        "from sklearn import datasets\n",
        "\n",
        "#Load dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "```\n",
        "\n",
        "*   Apply **GridSearchCV** to different classification algorithms such as **SVM, kNN, LogisticRegression, RandomForest**.\n",
        "*   Compare the results obtained by the best hyperparameters among classification algorithms."
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import scikit-learn dataset library\n",
        "from sklearn import datasets\n",
        "\n",
        "# Load dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "6ih3xCngZDm3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.1. Apply **GridSearchCV** to **SVM**\n"
      ],
      "metadata": {
        "id": "pnoVB8J4vV36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "#code\n",
        "param_grid_svm = {'C': [0.1, 1, 10, 100],\n",
        "              'degree': [1, 2, 3,],\n",
        "              'kernel': ['rbf','linear']}\n",
        "svm_alg = svm.SVC(kernel=\"poly\")\n",
        "\n",
        "grid_svm = GridSearchCV(\n",
        "    estimator= svm_alg,\n",
        "    param_grid= param_grid_svm,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=2,\n",
        "    cv =5,\n",
        "    refit = True,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "grid_svm.fit(X_train, y_train)\n",
        "\n",
        "best_svm = grid_svm.best_params_\n",
        "best_svm_score = grid_svm.best_score_\n",
        "print(\"Best parameter: \" , best_svm)\n",
        "\n",
        "y_pred = grid_svm.predict(X_test)\n",
        "accuracy_svm = accuracy_score(y_test, y_pred)\n",
        "precision_svm = precision_score(y_test, y_pred, average='macro')\n",
        "recall_svm = recall_score(y_test, y_pred, average='macro')\n",
        "f1_svm= f1_score(y_test, y_pred, average='macro')\n"
      ],
      "metadata": {
        "id": "-ZTSvsJdvYqI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d99d4851-0e86-447e-8ba1-08c29720c2cb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameter:  {'C': 100, 'degree': 1, 'kernel': 'linear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.2. Apply **GridSearchCV** to **kNN**"
      ],
      "metadata": {
        "id": "ol1U_T_NvcqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "param_grid_Knn = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "                  'leaf_size': [20, 30, 49],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "grid_Knn = GridSearchCV(\n",
        "    estimator= knn,\n",
        "    param_grid= param_grid_Knn,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=2,\n",
        "    cv =5,\n",
        "    refit = True,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "grid_Knn.fit(X_train, y_train)\n",
        "\n",
        "best_Knn = grid_Knn.best_params_\n",
        "best_Knn_score = grid_Knn.best_score_\n",
        "\n",
        "print(\"Best parameter: \" , best_Knn)\n",
        "print(\"Score: \" , best_Knn_score)\n",
        "\n",
        "y_pred = grid_Knn.predict(X_test)\n",
        "accuracy_Knn = accuracy_score(y_test, y_pred)\n",
        "precision_Knn = precision_score(y_test, y_pred, average='macro')\n",
        "recall_Knn = recall_score(y_test, y_pred, average='macro')\n",
        "f1_Knn= f1_score(y_test, y_pred, average='macro')"
      ],
      "metadata": {
        "id": "kt71yrAoBwYE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bbe467c8-9e9a-428e-af30-c6ecb1b57fa4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameter:  {'leaf_size': 20, 'metric': 'manhattan', 'n_neighbors': 5}\n",
            "Score:  0.9245886075949368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.3. Apply **GridSearchCV** to **LogisticRegression**"
      ],
      "metadata": {
        "id": "pPkAvse-BxNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "param_grid_logistic= {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.1, 1, 10],\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'max_iter': [100, 500, 1000]\n",
        "}\n",
        "Logistic = LogisticRegression()\n",
        "\n",
        "grid_logistic = GridSearchCV(\n",
        "    estimator= Logistic,\n",
        "    param_grid= param_grid_logistic,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=2,\n",
        "    cv =5,\n",
        "    refit = True,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "grid_logistic.fit(X_train, y_train)\n",
        "\n",
        "best_logistic = grid_logistic.best_params_\n",
        "best_logistic_score = grid_logistic.best_score_\n",
        "\n",
        "print(\"Best parameter: \" , best_logistic)\n",
        "print(\"Score: \" , best_logistic_score)\n",
        "\n",
        "y_pred_Logistic = grid_logistic.predict(X_test)\n",
        "accuracy_Logistic = accuracy_score(y_test, y_pred_Logistic)\n",
        "precision_Logistic = precision_score(y_test, y_pred_Logistic, average='macro')\n",
        "recall_Logistic = recall_score(y_test, y_pred_Logistic, average='macro')\n",
        "f1_Logistic = f1_score(y_test, y_pred_Logistic, average='macro')"
      ],
      "metadata": {
        "id": "nyYjpHFbB1Ci",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4fdd1c28-695f-4de1-8b83-1323a38b6506"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameter:  {'C': 10, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Score:  0.9697784810126582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.4. Apply **GridSearchCV** to **RandomForest**"
      ],
      "metadata": {
        "id": "3NjSLo5jB1xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "}\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "grid_rf = GridSearchCV(\n",
        "    estimator= clf,\n",
        "    param_grid= param_grid_rf,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=2,\n",
        "    cv =5,\n",
        "    refit = True,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "best_rf = grid_rf.best_params_\n",
        "best_rf_score = grid_rf.best_score_\n",
        "print(\"Best parameter: \" , best_rf)\n",
        "print(\"Score: \" , best_rf_score)\n",
        "\n",
        "y_pred = grid_rf.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred)\n",
        "precision_rf = precision_score(y_test, y_pred, average='macro')\n",
        "recall_rf = recall_score(y_test, y_pred, average='macro')\n",
        "f1_rf= f1_score(y_test, y_pred, average='macro')"
      ],
      "metadata": {
        "id": "nktGtM0PB7XB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c0b8a40d-f531-415d-b2d3-26401afb4f71"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameter:  {'max_depth': 20, 'max_features': 'sqrt', 'n_estimators': 100}\n",
            "Score:  0.9647435897435898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.5. Compare the best obtained results among classification algorithms (use PrettyTable to dispaly the results)"
      ],
      "metadata": {
        "id": "NZJ3BSHpB9Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "table = PrettyTable()\n",
        "table.field_names = ['ALGORITHM', 'ACC','PRE','RECALL', 'F1']\n",
        "table.add_row(['SVM', accuracy_svm, precision_svm, recall_svm, f1_svm])\n",
        "table.add_row(['Knn', accuracy_Knn, precision_Knn, recall_Knn, f1_Knn])\n",
        "table.add_row(['LogisticRegression', accuracy_Logistic, precision_Logistic, recall_Logistic, f1_Logistic])\n",
        "table.add_row(['Random Forest', accuracy_rf, precision_rf, recall_rf, f1_rf])\n",
        "print(table)"
      ],
      "metadata": {
        "id": "8LS_IYfNCFEj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d712db3c-e7ae-471d-df59-c69c0a775530"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|     ALGORITHM      |        ACC         |        PRE         |       RECALL       |         F1         |\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|        SVM         | 0.9473684210526315 | 0.9422459112149533 | 0.9451058201058201 | 0.9436366965757188 |\n",
            "|        Knn         | 0.9590643274853801 | 0.9608108108108109 | 0.951058201058201  | 0.9555629802873372 |\n",
            "| LogisticRegression | 0.9707602339181286 | 0.9672167056074766 | 0.9702380952380952 | 0.9686870536531771 |\n",
            "|   Random Forest    | 0.9707602339181286 | 0.9736486486486486 | 0.9636243386243386 | 0.9682592716338123 |\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. With **mobile price classification** dataset\n",
        "* 3.1.  Apply **GridSearchCV** for **SVM, kNN, RandomForest** algorithms to find the best hyperparameters for each classification algorithm.\n",
        "* 3.2. Compare the best obtained results among classification algorithms (use PrettyTable to dispaly the results)"
      ],
      "metadata": {
        "id": "az26oYW1Yxuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/dataLab6'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9oFY4sLMKilH",
        "outputId": "c7d094e2-a3f6-41a1-b07c-225e66c13657"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/dataLab6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "mobile = pd.read_csv(\"mobile.csv\")\n",
        "\n",
        "X = mobile.drop(columns='price_range');\n",
        "y = mobile['price_range']\n",
        "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "_jsYpiNYWxXK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "svm\n"
      ],
      "metadata": {
        "id": "Xm9M_jVCWt8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# param_grid\n",
        "param_grid_svm = {'C': [0.1, 1, 10, 100],\n",
        "              'gamma': ['scale', 'auto'],\n",
        "              'kernel': ['rbf','linear']}\n",
        "svm_alg = svm.SVC(kernel=\"sigmoid\")\n",
        "\n",
        "grid_svm = GridSearchCV(\n",
        "    estimator= svm_alg,\n",
        "    param_grid= param_grid_svm,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=2,\n",
        "    cv =5,\n",
        "    refit = True,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "grid_svm.fit(X_train, y_train)\n",
        "\n",
        "best_svm = grid_svm.best_params_\n",
        "best_svm_score = grid_svm.best_score_\n",
        "print(\"Best parameter: \" , best_svm)\n",
        "\n",
        "y_pred = grid_svm.predict(X_test)\n",
        "accuracy_svm = accuracy_score(y_test, y_pred)\n",
        "precision_svm = precision_score(y_test, y_pred, average='macro')\n",
        "recall_svm = recall_score(y_test, y_pred, average='macro')\n",
        "f1_svm= f1_score(y_test, y_pred, average='macro')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MFZUE8CDK_B5",
        "outputId": "b8482f44-719a-4474-9737-958ab8205817"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameter:  {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Knn\n",
        "#code\n",
        "param_grid_Knn = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "                  'p': [1, 2],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "grid_Knn = GridSearchCV(\n",
        "    estimator= knn,\n",
        "    param_grid= param_grid_Knn,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=2,\n",
        "    cv =5,\n",
        "    refit = True,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "grid_Knn.fit(X_train, y_train)\n",
        "\n",
        "best_Knn = grid_Knn.best_params_\n",
        "best_Knn_score = grid_Knn.best_score_\n",
        "\n",
        "print(\"Best parameter: \" , best_Knn)\n",
        "print(\"Score: \" , best_Knn_score)\n",
        "\n",
        "y_pred = grid_Knn.predict(X_test)\n",
        "accuracy_Knn = accuracy_score(y_test, y_pred)\n",
        "precision_Knn = precision_score(y_test, y_pred, average='macro')\n",
        "recall_Knn = recall_score(y_test, y_pred, average='macro')\n",
        "f1_Knn= f1_score(y_test, y_pred, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bjp1c3J2LCUZ",
        "outputId": "51b5b97a-3387-4072-d1aa-026ece7ad828"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameter:  {'metric': 'minkowski', 'n_neighbors': 11, 'p': 1}\n",
            "Score:  0.9278571428571428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# randomForest\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "}\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "grid_rf = GridSearchCV(\n",
        "    estimator= clf,\n",
        "    param_grid= param_grid_rf,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=2,\n",
        "    cv =5,\n",
        "    refit = True,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "best_rf = grid_rf.best_params_\n",
        "best_rf_score = grid_rf.best_score_\n",
        "print(\"Best parameter: \" , best_rf)\n",
        "print(\"Score: \" , best_rf_score)\n",
        "\n",
        "y_pred = grid_rf.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred)\n",
        "precision_rf = precision_score(y_test, y_pred, average='macro')\n",
        "recall_rf = recall_score(y_test, y_pred, average='macro')\n",
        "f1_rf= f1_score(y_test, y_pred, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pJElkr4sLFDJ",
        "outputId": "4959dd0b-4ba9-4f7c-fc36-008ed54c3ba3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameter:  {'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 200}\n",
            "Score:  0.8742857142857142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# table\n",
        "#code\n",
        "table = PrettyTable()\n",
        "table.field_names = ['ALGORITHM', 'ACC','PRE','RECALL', 'F1']\n",
        "table.add_row(['SVM', accuracy_svm, precision_svm, recall_svm, f1_svm])\n",
        "table.add_row(['Knn', accuracy_Knn, precision_Knn, recall_Knn, f1_Knn])\n",
        "table.add_row(['Random Forest', accuracy_rf, precision_rf, recall_rf, f1_rf])\n",
        "print(table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5nKqALXKLLZE",
        "outputId": "9fdf6a10-e08c-4f17-b48e-905f2323743d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|   ALGORITHM   |        ACC         |        PRE         |       RECALL       |         F1         |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|      SVM      | 0.9716666666666667 | 0.972471369661605  | 0.9717902879380128 | 0.9716066846130056 |\n",
            "|      Knn      |       0.935        | 0.9353909348400757 | 0.9349434508459408 | 0.9347920595433563 |\n",
            "| Random Forest | 0.8766666666666667 | 0.8755644743050954 | 0.8759695646283221 | 0.8756795330843103 |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4.\n",
        "The dataset consists of **2000 user-created movie reviews** archived on the IMDb(Internet Movie Database). The reviews are equally partitioned into a positive set and a negative set (1000+1000). Each review consists of a plain text file (.txt) and a class label representing the overall user opinion.\n",
        "The class attribute has only two values: **pos** (positive) or **neg** (negative).\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.1 Importing additional libraries"
      ],
      "metadata": {
        "id": "lDcxOQRmDz_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk, random\n",
        "nltk.download('movie_reviews')#download movie reviews dataset\n",
        "from nltk.corpus import movie_reviews\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ZjyW06skDwvL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e398d4fe-3338-419b-e539-3984c9aa0dd6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.2. Movie reviews information"
      ],
      "metadata": {
        "id": "RJpsTIiyv-1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "print(len(movie_reviews.fileids()))\n",
        "print(movie_reviews.categories())\n",
        "print(movie_reviews.words()[:100])\n",
        "print(movie_reviews.fileids()[:10])"
      ],
      "metadata": {
        "id": "5ZE7A0Au1Pg0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a0289964-1547-43c1-9ed3-134a07183a47"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n",
            "['neg', 'pos']\n",
            "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', ...]\n",
            "['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt', 'neg/cv003_12683.txt', 'neg/cv004_12641.txt', 'neg/cv005_29357.txt', 'neg/cv006_17022.txt', 'neg/cv007_4992.txt', 'neg/cv008_29326.txt', 'neg/cv009_29417.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.3. Create dataset from movie reviews"
      ],
      "metadata": {
        "id": "6pHmMpqMHS23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "random.seed(123)\n",
        "random.shuffle(documents)"
      ],
      "metadata": {
        "id": "45aY6woMHSH5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of Reviews/Documents: {}'.format(len(documents)))\n",
        "print('Corpus Size (words): {}'.format(np.sum([len(d) for (d,l) in documents])))\n",
        "print('Sample Text of Doc 1:')\n",
        "print('-'*30)\n",
        "print(' '.join(documents[0][0][:50])) # first 50 words of the first document"
      ],
      "metadata": {
        "id": "NNke0Da5HqFa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1630509b-15af-4b0b-c49c-23b4fc2dd308"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Reviews/Documents: 2000\n",
            "Corpus Size (words): 1583820\n",
            "Sample Text of Doc 1:\n",
            "------------------------------\n",
            "most movies seem to release a third movie just so it can be called a trilogy . rocky iii seems to kind of fit in that category , but manages to be slightly unique . the rocky formula of \" rocky loses fight / rocky trains / rocky wins fight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_distr = Counter([label for (words, label) in documents])\n",
        "print(sentiment_distr)"
      ],
      "metadata": {
        "id": "vVFUEhnXHsGd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "46a8d47c-61f9-404b-9369-3ce2f909bfc2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'pos': 1000, 'neg': 1000})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.4. Train test split"
      ],
      "metadata": {
        "id": "jTXiEbMzHgVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(documents, test_size = 0.33, random_state=42)"
      ],
      "metadata": {
        "id": "v_-0gZZFHvJN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Sentiment Distrubtion for Train and Test\n",
        "print(Counter([label for (words, label) in train]))\n",
        "print(Counter([label for (words, label) in test]))"
      ],
      "metadata": {
        "id": "UUGlm5TGHvpV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d24730dc-9285-4c6f-dd3b-d02780ecde9a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'neg': 674, 'pos': 666})\n",
            "Counter({'pos': 334, 'neg': 326})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [' '.join(words) for (words, label) in train]\n",
        "X_test = [' '.join(words) for (words, label) in test]\n",
        "y_train = [label for (words, label) in train]\n",
        "y_test = [label for (words, label) in test]"
      ],
      "metadata": {
        "id": "l1ppl_0RHx1P"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.5. Text Vectorization"
      ],
      "metadata": {
        "id": "7xUaXrjxH6Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "tfidf_vec = TfidfVectorizer(min_df = 10, token_pattern = r'[a-zA-Z]+')\n",
        "X_train_bow = tfidf_vec.fit_transform(X_train) # fit train\n",
        "X_test_bow = tfidf_vec.transform(X_test) # transform test"
      ],
      "metadata": {
        "id": "fzwM0nsIH-8l"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.6. Apply **SVM** with **GridSearchCV**"
      ],
      "metadata": {
        "id": "BP1vB3loIF28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "# param_grid\n",
        "param_grid_svm = {'C': [0.1, 1, 10, 100],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001],\n",
        "              'kernel': ['poly','linear']}\n",
        "svm_alg = svm.SVC(kernel=\"sigmoid\")\n",
        "\n",
        "grid_svm = GridSearchCV(\n",
        "    estimator= svm_alg,\n",
        "    param_grid= param_grid_svm,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=2,\n",
        "    cv =5,\n",
        "    refit = True,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "grid_svm.fit(X_train_bow, y_train)\n",
        "\n",
        "best_svm = grid_svm.best_params_\n",
        "best_svm_score = grid_svm.best_score_\n",
        "print(\"Best parameter: \" , best_svm)\n",
        "\n",
        "y_pred = grid_svm.predict(X_test_bow)\n",
        "accuracy_svm = accuracy_score(y_test, y_pred)\n",
        "precision_svm = precision_score(y_test, y_pred, average='macro')\n",
        "recall_svm = recall_score(y_test, y_pred, average='macro')\n",
        "f1_svm= f1_score(y_test, y_pred, average='macro')\n"
      ],
      "metadata": {
        "id": "b3FHQqh1Hlrd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "32d821c6-529c-41f9-b0c8-049360f887b8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameter:  {'C': 1, 'gamma': 1, 'kernel': 'linear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.7. Apply **RandomForest** with **GridSearchCV**"
      ],
      "metadata": {
        "id": "N1Fy8jYBIdxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "}\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "grid_rf = GridSearchCV(\n",
        "    estimator= clf,\n",
        "    param_grid= param_grid_rf,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=2,\n",
        "    cv =5,\n",
        "    refit = True,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "grid_rf.fit(X_train_bow, y_train)\n",
        "\n",
        "best_rf = grid_rf.best_params_\n",
        "best_rf_score = grid_rf.best_score_\n",
        "print(\"Best parameter: \" , best_rf)\n",
        "print(\"Score: \" , best_rf_score)\n",
        "\n",
        "y_pred = grid_rf.predict(X_test_bow)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred)\n",
        "precision_rf = precision_score(y_test, y_pred, average='macro')\n",
        "recall_rf = recall_score(y_test, y_pred, average='macro')\n",
        "f1_rf= f1_score(y_test, y_pred, average='macro')"
      ],
      "metadata": {
        "id": "Fyfw2R-gIhWl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c132938b-c22c-4ff9-97f7-cab9fde2575c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameter:  {'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Score:  0.8126865671641792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.8. Apply **kNN** with **GridSearchCV**"
      ],
      "metadata": {
        "id": "_btsVKjIIiLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "param_grid_Knn = { 'n_neighbors' : [5,7,9,11],\n",
        "                  'algorithm': [ 'ball_tree', 'kd_tree', 'brute'],\n",
        "                'metric' : ['minkowski','euclidean','manhattan']}\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "grid_Knn = GridSearchCV(\n",
        "    estimator= knn,\n",
        "    param_grid= param_grid_Knn,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=2,\n",
        "    cv =5,\n",
        "    refit = True,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "grid_Knn.fit(X_train_bow, y_train)\n",
        "\n",
        "best_Knn = grid_Knn.best_params_\n",
        "best_Knn_score = grid_Knn.best_score_\n",
        "\n",
        "print(\"Best parameter: \" , best_Knn)\n",
        "print(\"Score: \" , best_Knn_score)\n",
        "\n",
        "y_pred = grid_Knn.predict(X_test_bow)\n",
        "accuracy_Knn = accuracy_score(y_test, y_pred)\n",
        "precision_Knn = precision_score(y_test, y_pred, average='macro')\n",
        "recall_Knn = recall_score(y_test, y_pred, average='macro')\n",
        "f1_Knn= f1_score(y_test, y_pred, average='macro')"
      ],
      "metadata": {
        "id": "IZmFu1ZQImhn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "683b4e11-ffb0-41cd-f765-ee0b9d4f64eb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_base.py:557: UserWarning: cannot use tree with sparse input: using brute force\n",
            "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameter:  {'algorithm': 'ball_tree', 'metric': 'manhattan', 'n_neighbors': 11}\n",
            "Score:  0.6246268656716418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.9. Apply **LogisticRegression** with **GridSearchCV**"
      ],
      "metadata": {
        "id": "0Ix_HeVGIvDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "param_grid_logistic= {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.1, 1, 10],\n",
        "    'class_weight': [None, 'balanced'],\n",
        "    'max_iter': [100, 500, 1000]\n",
        "}\n",
        "Logistic = LogisticRegression()\n",
        "\n",
        "grid_logistic = GridSearchCV(\n",
        "    estimator= Logistic,\n",
        "    param_grid= param_grid_logistic,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=2,\n",
        "    cv =5,\n",
        "    refit = True,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "grid_logistic.fit(X_train_bow, y_train)\n",
        "\n",
        "best_logistic = grid_logistic.best_params_\n",
        "best_logistic_score = grid_logistic.best_score_\n",
        "\n",
        "print(\"Best parameter: \" , best_logistic)\n",
        "print(\"Score: \" , best_logistic_score)\n",
        "\n",
        "y_pred_Logistic = grid_logistic.predict(X_test_bow)\n",
        "accuracy_Logistic = accuracy_score(y_test, y_pred_Logistic)\n",
        "precision_Logistic = precision_score(y_test, y_pred_Logistic, average='macro')\n",
        "recall_Logistic = recall_score(y_test, y_pred_Logistic, average='macro')\n",
        "f1_Logistic = f1_score(y_test, y_pred_Logistic, average='macro')"
      ],
      "metadata": {
        "id": "sTd3alCMIr-i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fefbfb81-1959-4815-b25f-93fed79ceb35"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "90 fits failed out of a total of 180.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "90 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.75970149        nan 0.75970149        nan 0.75970149\n",
            "        nan 0.75746269        nan 0.75746269        nan 0.75746269\n",
            "        nan 0.81343284        nan 0.81343284        nan 0.81343284\n",
            "        nan 0.81044776        nan 0.81044776        nan 0.81044776\n",
            "        nan 0.84925373        nan 0.84925373        nan 0.84925373\n",
            "        nan 0.84925373        nan 0.84925373        nan 0.84925373]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan 0.84514925        nan 0.84514925        nan 0.84514925\n",
            "        nan 0.84682836        nan 0.84682836        nan 0.84682836\n",
            "        nan 0.9380597         nan 0.9380597         nan 0.9380597\n",
            "        nan 0.9375            nan 0.9375            nan 0.9375\n",
            "        nan 0.9994403         nan 0.9994403         nan 0.9994403\n",
            "        nan 0.9994403         nan 0.9994403         nan 0.9994403 ]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameter:  {'C': 10, 'class_weight': None, 'max_iter': 100, 'penalty': 'l2'}\n",
            "Score:  0.8492537313432835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   4.10. Compare the best obtained results among classification algorithms (use PrettyTable to dispaly the results)"
      ],
      "metadata": {
        "id": "nhYF2y6eI058"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "table = PrettyTable()\n",
        "table.field_names = ['ALGORITHM', 'ACC','PRE','RECALL', 'F1']\n",
        "table.add_row(['SVM', accuracy_svm, precision_svm, recall_svm, f1_svm])\n",
        "table.add_row(['Random Forest', accuracy_rf, precision_rf, recall_rf, f1_rf])\n",
        "table.add_row(['Knn', accuracy_Knn, precision_Knn, recall_Knn, f1_Knn])\n",
        "table.add_row(['LogisticRegression', accuracy_Logistic, precision_Logistic, recall_Logistic, f1_Logistic])\n",
        "print(table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SB6xSfLUd3-6",
        "outputId": "f8204857-8dd2-4b44-8e7a-8da9294a6ce3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|     ALGORITHM      |        ACC         |        PRE         |       RECALL       |         F1         |\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|        SVM         | 0.8106060606060606 | 0.811119499866496  | 0.810339443811763  | 0.8104141244924269 |\n",
            "|   Random Forest    | 0.803030303030303  | 0.8034926470588235 | 0.8032585136475515 | 0.8030140231975094 |\n",
            "|        Knn         | 0.6545454545454545 | 0.6567463290380582 | 0.653723228389846  | 0.6525513738166705 |\n",
            "| LogisticRegression | 0.8227272727272728 | 0.8229897637288354 | 0.8225359097755409 | 0.8226095825742975 |\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}